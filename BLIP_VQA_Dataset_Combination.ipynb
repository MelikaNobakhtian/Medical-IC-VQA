{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP0LROIxGBhO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import json\n",
        "from bert_score import score\n",
        "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\"\"\"save execution time\"\"\"\n",
        "start_time = time.time()\n",
        "\n",
        "\"\"\"necessary paths\"\"\"\n",
        "path = '/content/mvqa_dataset/'\n",
        "train_path = path + 'train'\n",
        "test_path_rad = path + 'test/vqa-rad'\n",
        "test_path_slake = path + 'test/slake'\n",
        "test_path_mvqa = path + 'test/mvqa'\n",
        "\n",
        "each_n_epoch = 2\n",
        "version = 1\n",
        "im_size = (224, 224)\n",
        "epochs = 5\n",
        "should_save_weights = True\n",
        "\n",
        "\"\"\"create necessary folders\"\"\"\n",
        "model_path = path + \"runs/\" + str(version)\n",
        "os.makedirs(model_path + \"/results\", exist_ok=True)\n",
        "os.makedirs(model_path + \"/weights\", exist_ok=True)\n",
        "\n",
        "\"\"\"define limit for data loading\"\"\"\n",
        "sample = True\n",
        "train_limit = 3000\n",
        "### what about this?\n",
        "test_limit = 500\n",
        "\n",
        "dataset_batchsize = 4\n",
        "\n",
        "train_img_path = train_path + '/images'\n",
        "test_img_rad = test_path_rad + '/images'\n",
        "test_img_slake = test_path_slake + '/images'\n",
        "test_img_mvqa = test_path_mvqa + '/images'\n",
        "\n",
        "existing_train_img_names = []\n",
        "for root, dirs, files in os.walk(train_img_path, topdown=False):\n",
        "    for name in files:\n",
        "        existing_train_img_names.append(name)\n",
        "\n",
        "existing_test_img_rad_names = []\n",
        "for root, dirs, files in os.walk(test_img_rad, topdown=False):\n",
        "    for name in files:\n",
        "        existing_test_img_rad_names.append(name)\n",
        "\n",
        "existing_test_img_slake_names = []\n",
        "for root, dirs, files in os.walk(test_img_slake, topdown=False):\n",
        "    for name in files:\n",
        "        existing_test_img_slake_names.append(name)\n",
        "\n",
        "existing_test_img_mvqa_names = []\n",
        "for root, dirs, files in os.walk(test_img_mvqa, topdown=False):\n",
        "    for name in files:\n",
        "        existing_test_img_mvqa_names.append(name)\n",
        "\n",
        "\"\"\"read csv files\"\"\"\n",
        "train_df = (\n",
        "    pd.read_csv(\n",
        "        train_path + \"/train_EN.csv\",\n",
        "        index_col=\"name\",\n",
        "    )\n",
        ").filter(items=existing_train_img_names, axis=0)\n",
        "\n",
        "if sample:\n",
        "    train_df = train_df.sample(train_limit).sort_values(by=[\"ID\"])\n",
        "\n",
        "print(f\"- read {len(train_df)} train images\")\n",
        "\n",
        "test_df_rad = (\n",
        "    pd.read_csv(\n",
        "        test_path_rad + \"/radiologytestdata.csv\",\n",
        "        index_col=\"ID\",\n",
        "    )\n",
        ").filter(items=existing_test_img_rad_names, axis=0)\n",
        "\n",
        "if sample:\n",
        "    test_df_rad = test_df_rad.sample(test_limit).sort_values(by=[\"ID\"])\n",
        "\n",
        "print(f\"- read {len(test_df_rad)} rad test images\")\n",
        "\n",
        "test_df_slake = (\n",
        "    pd.read_csv(\n",
        "        test_path_slake + \"/radiologytestdata.csv\",\n",
        "        index_col=\"ID\",\n",
        "    )\n",
        ").filter(items=existing_test_img_slake_names, axis=0)\n",
        "\n",
        "if sample:\n",
        "    test_df_slake = test_df_slake.sample(test_limit).sort_values(by=[\"ID\"])\n",
        "\n",
        "print(f\"- read {len(test_df_slake)} slake test images\")\n",
        "\n",
        "test_df_mvqa = (\n",
        "    pd.read_csv(\n",
        "        test_path_mvqa + \"/radiologytestdata.csv\",\n",
        "        index_col=\"ID\",\n",
        "    )\n",
        ").filter(items=existing_test_img_mvqa_names, axis=0)\n",
        "\n",
        "if sample:\n",
        "    test_df_mvqa = test_df_mvqa.sample(test_limit).sort_values(by=[\"ID\"])\n",
        "\n",
        "print(f\"- read {len(test_df_mvqa)} mvqa test images\")\n",
        "\n",
        "\"\"\"Save image names as list\"\"\"\n",
        "train_img_names = train_df.index.values.tolist()\n",
        "test_img_rad_names = test_df_rad.index.values.tolist()\n",
        "test_img_slake_names = test_df_slake.index.values.tolist()\n",
        "test_img_mvqa_names = test_df_mvqa.index.values.tolist()\n",
        "\n",
        "class VQADataset(Dataset):\n",
        "    def __init__(self, folder_path, image_list, dataset_df, processor):\n",
        "        self.folder_path = folder_path\n",
        "        self.image_list = image_list\n",
        "        self.processor = processor\n",
        "        self.dataset_df = dataset_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_list[idx]\n",
        "        img_path = self.image_path + '/' + img_name\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        q = self.dataset_df.iloc[idx]['question']\n",
        "        ans = self.dataset_df.iloc[idx]['answer']\n",
        "        encoding = self.processor(images=img, text=[q, str(ans)], padding=\"max_length\", return_tensors=\"pt\")\n",
        "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
        "        encoding['labels'] = encoding['input_ids'][1][:512]\n",
        "        encoding['input_ids'] = encoding['input_ids'][0][:512]\n",
        "        encoding['attention_mask'] = [entry[:512] for entry in encoding['attention_mask']]\n",
        "        return encoding\n",
        "\n",
        "\"\"\"Load processors and models\"\"\"\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(\"cuda\")\n",
        "\n",
        "\"\"\"Generate Dataset and Dataloaders\"\"\"\n",
        "train_dataset = VQADataset(folder_path=train_img_path, image_list=train_img_names, dataset_df=train_df, processor=processor)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=dataset_batchsize)\n",
        "\n",
        "\"\"\"Predicting\"\"\"\n",
        "def pred_vqa(image, question):\n",
        "    inputs = processor(images=image, text=question, return_tensors=\"pt\").to(device)\n",
        "    pixel_values = inputs.pixel_values\n",
        "    input_ids = inputs.input_ids\n",
        "\n",
        "    generated_ids = model.generate(pixel_values=pixel_values, input_ids=input_ids, max_length=50)\n",
        "    generated_answer = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return generated_answer\n",
        "\n",
        "def predict_test_dataframe(image_path, image_list, df, dataset_name, epoch):\n",
        "    preds = []\n",
        "    for idx, name in enumerate(image_list):\n",
        "        im_path = image_path + \"/\" + name\n",
        "        img = Image.open(im_path)\n",
        "        q = df.iloc[idx]['question']\n",
        "        ans = pred_vqa(img, q)\n",
        "        preds.append(ans)\n",
        "\n",
        "    filename = f\"e-{epoch}-test-{dataset_name}-caption-v{version}.csv\"\n",
        "    df_pred = pd.DataFrame(\n",
        "        data={\n",
        "            \"ID\": image_list,\n",
        "            \"question\": df['question'].tolist(),\n",
        "            \"answer\": preds,\n",
        "            \"answer_type\":df['answer_type'].tolist()\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df_pred.to_csv(\n",
        "        model_path + \"/results/\" + filename, index=False, header=None\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_accuracy(true_df, pred_df):\n",
        "    \"\"\"all data\"\"\"\n",
        "    true_ans =  [str(ans).lower() for ans in true_df['answer'].tolist()]\n",
        "    pred_ans = [ans.lower() for ans in pred_df['answer'].tolist()]\n",
        "    acc_all = accuracy_score(true_ans, pred_ans)\n",
        "    \"\"\"open questions\"\"\"\n",
        "    true_ans =  [str(ans).lower() for ans in true_df.loc[true_df['answer_type'] == \"OPEN\"]['answer'].tolist()]\n",
        "    pred_ans =  [ans.lower() for ans in pred_df.loc[pred_df['answer_type'] == \"OPEN\"]['answer'].tolist()]\n",
        "    acc_open = accuracy_score(true_ans, pred_ans)\n",
        "    \"\"\"close questions\"\"\"\n",
        "    true_ans =  [str(ans).lower() for ans in true_df.loc[true_df['answer_type'] == \"CLOSED\"]['answer'].tolist()]\n",
        "    pred_ans =  [ans.lower() for ans in pred_df.loc[pred_df['answer_type'] == \"CLOSED\"]['answer'].tolist()]\n",
        "    acc_closed = accuracy_score(true_ans, pred_ans)\n",
        "\n",
        "    return acc_all, acc_open, acc_closed\n",
        "\n",
        "\n",
        "def predict_and_save(model, epoch):\n",
        "    \"\"\"pred test datasets - RAD, MVQA, SLAKE\"\"\"\n",
        "    pred_df_rad = predict_test_dataframe(test_img_rad, test_img_rad_names, test_df_rad, 'rad', epoch)\n",
        "    pred_df_mvqa = predict_test_dataframe(test_img_mvqa, test_img_mvqa_names, test_df_mvqa, 'mvqa', epoch)\n",
        "    pred_df_slake = predict_test_dataframe(test_img_slake, test_img_slake_names, test_df_slake, 'slake', epoch)\n",
        "\n",
        "    \"\"\"compute scores for test data\"\"\"\n",
        "    rad_all, rad_open, rad_closed = calculate_accuracy(test_df_rad, pred_df_rad)\n",
        "    slake_all, slake_open, slake_closed = calculate_accuracy(test_df_slake, pred_df_slake)\n",
        "    mvqa_all, mvqa_open, mvqa_closed = calculate_accuracy(test_df_mvqa, pred_df_mvqa)\n",
        "    score_df = pd.DataFrame(data={'All':[rad_all, slake_all, mvqa_all],\n",
        "                                  'Open':[rad_open, slake_open, mvqa_open],\n",
        "                                  \"Closed\":[rad_closed, slake_closed, mvqa_closed]},\n",
        "                            index=['RAD', 'SLAKE', 'MVQA'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    filename = f\"e-{epoch}-test-scores-v{version}.csv\"\n",
        "    score_df.to_csv(\n",
        "        model_path + \"/results/\" + filename\n",
        "    )\n",
        "\n",
        "\"\"\"Training\"\"\"\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Epoch:\", epoch+1)\n",
        "  train_loss = 0.0\n",
        "  batch_num = 1\n",
        "  for idx, batch in enumerate(train_dataloader):\n",
        "    print(\"Batch: \", str(batch_num))\n",
        "    batch_num +=1\n",
        "    torch.cuda.empty_cache()\n",
        "    input_ids = batch.pop(\"input_ids\").to(device)\n",
        "    pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "    labels = batch.pop(\"labels\").to(device)\n",
        "\n",
        "    outputs = model(input_ids=input_ids,\n",
        "                    pixel_values=pixel_values,\n",
        "                    labels=input_ids)\n",
        "\n",
        "    loss = outputs.loss\n",
        "    train_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  # Compute the average loss for the training dataset\n",
        "  train_loss /= len(train_dataloader.dataset)\n",
        "\n",
        "  # Print the training and validation losses for each epoch\n",
        "  print('Epoch [{}/{}], Train Loss: {:.4f}'\n",
        "        .format(epoch + 1, epochs, train_loss))\n",
        "\n",
        "  if epoch == 0 or (epoch + 1) % each_n_epoch == 0:\n",
        "      predict_and_save(model, epoch + 1)\n",
        "      os.makedirs(model_path + \"/weights/epoch\" + str(epoch+1) , exist_ok=True)\n",
        "      model.save_pretrained(model_path + \"/weights/epoch\" + str(epoch+1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(model_path + \"/results/running_time.json\", \"w+\") as f:\n",
        "    json.dump({\n",
        "        \"task\": \"caption\",\n",
        "        \"total_running_time_mins\": (time.time() - start_time) / 60,\n",
        "        \"version\": version,\n",
        "    }, f)\n",
        "\n",
        "\n",
        ""
      ]
    }
  ]
}