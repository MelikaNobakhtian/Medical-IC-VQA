{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Just need for Colab"
      ],
      "metadata": {
        "id": "vukcVAW-kgGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IqH7HydQeOc"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/roco-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main\n",
        "!pip install bert-score"
      ],
      "metadata": {
        "id": "RsHmkij5R6Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/all_data/train/radiologytraindata.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "ONKRy4FFFWtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = (\n",
        "    pd.read_csv(\n",
        "        \"/content/all_data/train/radiologytraindata.csv\",\n",
        "        index_col=\"name\",\n",
        "    )\n",
        ").filter(items=existing_train_img_names, axis=0)"
      ],
      "metadata": {
        "id": "upioGEFdMKQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_names = train_df.index.values.tolist()\n",
        "len(train_img_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMBPk-6eQc72",
        "outputId": "062ff7ce-82a5-44c5-d309-e08228135548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65420"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_names"
      ],
      "metadata": {
        "id": "lac4EobfR8QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "JVrZFLTMMd31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = True\n",
        "train_limit = 200\n",
        "if sample:\n",
        "    train_df = df.sample(train_limit)"
      ],
      "metadata": {
        "id": "ZtyRD4BbFymX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "k4YJhoj7LdkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "existing_train_img_names = []\n",
        "for root, dirs, files in os.walk('/content/all_data/train/radiology', topdown=False):\n",
        "    for name in files:\n",
        "        existing_train_img_names.append(name)"
      ],
      "metadata": {
        "id": "i9jCACf8K8cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_train_img_names"
      ],
      "metadata": {
        "id": "4VcSG17kLVmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnYFzSI6GVmY",
        "outputId": "7b259ff5-d6ee-410c-eb9f-f93cd01c8c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "hEAL0aYVkmUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import json\n",
        "from bert_score import score\n",
        "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\"\"\"save execution time\"\"\"\n",
        "start_time = time.time()\n",
        "\n",
        "\"\"\"necessary paths\"\"\"\n",
        "path = '/content/all_data/'\n",
        "train_path = path + 'train'\n",
        "test_path = path + 'test'\n",
        "\n",
        "each_n_epoch = 2\n",
        "version = 1\n",
        "im_size = (224, 224)\n",
        "epochs = 5\n",
        "should_save_weights = True\n",
        "\n",
        "\"\"\"create necessary folders\"\"\"\n",
        "model_path = path + \"runs/\" + str(version)\n",
        "os.makedirs(model_path + \"/results\", exist_ok=True)\n",
        "os.makedirs(model_path + \"/weights\", exist_ok=True)\n",
        "\n",
        "\"\"\"define limit for data loading\"\"\"\n",
        "sample = True\n",
        "train_limit = 3000\n",
        "test_limit = 500\n",
        "\n",
        "dataset_batchsize = 4\n",
        "\n",
        "train_img_path = train_path + '/radiology/images'\n",
        "test_img_path = test_path + '/radiology/images'\n",
        "\n",
        "existing_train_img_names = []\n",
        "for root, dirs, files in os.walk(train_img_path, topdown=False):\n",
        "    for name in files:\n",
        "        existing_train_img_names.append(name)\n",
        "\n",
        "existing_test_img_names = []\n",
        "for root, dirs, files in os.walk(test_img_path, topdown=False):\n",
        "    for name in files:\n",
        "        existing_test_img_names.append(name)\n",
        "\n",
        "\"\"\"read csv files\"\"\"\n",
        "train_df = (\n",
        "    pd.read_csv(\n",
        "        train_path + \"/radiologytraindata.csv\",\n",
        "        index_col=\"name\",\n",
        "    )\n",
        ").filter(items=existing_train_img_names, axis=0)\n",
        "\n",
        "if sample:\n",
        "    train_df = train_df.sample(train_limit).sort_values(by=[\"name\"])\n",
        "\n",
        "print(f\"- read {len(train_df)} train images\")\n",
        "\n",
        "test_df = (\n",
        "    pd.read_csv(\n",
        "        test_path + \"/radiologytestdata.csv\",\n",
        "        index_col=\"name\",\n",
        "    )\n",
        ").filter(items=existing_test_img_names, axis=0)\n",
        "\n",
        "if sample:\n",
        "    test_df = test_df.sample(test_limit).sort_values(by=[\"name\"])\n",
        "\n",
        "print(f\"- read {len(test_df)} test images\")\n",
        "\n",
        "\"\"\"Save image names as list\"\"\"\n",
        "train_img_names = train_df.index.values.tolist()\n",
        "test_img_names = test_df.index.values.tolist()\n",
        "\n",
        "class ImageCaptioningDataset(Dataset):\n",
        "    def __init__(self, folder_path, image_list, dataset_df, processor):\n",
        "        self.folder_path = folder_path\n",
        "        self.image_list = image_list\n",
        "        self.processor = processor\n",
        "        self.dataset_df = dataset_df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_list[idx]\n",
        "        img_path = self.folder_path + \"/\" + img_name\n",
        "        img = Image.open(img_path)\n",
        "        img = img.convert('RGB')\n",
        "        img = img.resize(im_size)\n",
        "        caption = self.dataset_df.iloc[idx][\"caption\"]\n",
        "        encoding = self.processor(images=img, text=caption, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # remove batch dimension\n",
        "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
        "        encoding['input_ids'] = encoding['input_ids'][:512]\n",
        "        encoding['attention_mask'] = encoding['attention_mask'][:512]\n",
        "        return encoding\n",
        "\n",
        "\"\"\"Load processors and models\"\"\"\n",
        "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "\"\"\"Generate Dataset and Dataloaders\"\"\"\n",
        "train_dataset = ImageCaptioningDataset(folder_path=train_img_path, image_list=train_img_names, dataset_df=train_df, processor=processor)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=dataset_batchsize)\n",
        "\n",
        "\"\"\"Caculating Metrics - BLEU-4, ROUGE, BERTScore\"\"\"\n",
        "def calculate_bleu(preds, refs):\n",
        "    preds_split = [pred.split() for pred in preds]\n",
        "    refs_split = [[ref.split()] for ref in refs]\n",
        "    score = bleu_score(preds_split, refs_split)\n",
        "    return {'belu-4': score}\n",
        "\n",
        "def calculate_rouge(preds, refs):\n",
        "    rouge = ROUGEScore()\n",
        "    refs_list = [[ref] for ref in refs]\n",
        "    scores = rouge(preds, refs_list)\n",
        "    return scores\n",
        "\n",
        "def calculate_bertscore(preds, refs):\n",
        "    count = len(preds)\n",
        "    P, R, F1 = score(preds, refs, lang='en', verbose=False)\n",
        "    score_F1 = (torch.sum(F1) / count).item()\n",
        "    score_P = (torch.sum(P) / count).item()\n",
        "    score_R = (torch.sum(R) / count).item()\n",
        "    return {'bert-P': score_P, 'bert-R': score_R, 'bert-F1': score_F1}\n",
        "\n",
        "\n",
        "\"\"\"Predicting\"\"\"\n",
        "def pred_img_caption(image):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    pixel_values = inputs.pixel_values\n",
        "\n",
        "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return generated_caption\n",
        "\n",
        "def predict_and_save(model, epoch):\n",
        "    \"\"\"pred test dataset\"\"\"\n",
        "    preds = []\n",
        "    for name in test_img_names:\n",
        "        im_path = test_img_path + \"/\" + name\n",
        "        img = Image.open(im_path)\n",
        "        cap = pred_img_caption(img)\n",
        "        preds.append(cap)\n",
        "\n",
        "    filename = f\"e-{epoch}-test-caption-v{version}.csv\"\n",
        "    df = pd.DataFrame(\n",
        "        data={\n",
        "            \"ID\": test_img_names,\n",
        "            \"caption\": preds,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df.to_csv(\n",
        "        model_path + \"/results/\" + filename, index=False, header=None\n",
        "    )\n",
        "\n",
        "    \"\"\"compute scores for test data\"\"\"\n",
        "    refs = test_df['caption'].tolist()\n",
        "    bleu_score = calculate_bleu(preds, refs)\n",
        "    rouge_score = calculate_rouge(preds, refs)\n",
        "    bert_score = calculate_bertscore(preds, refs)\n",
        "    all_scores = {**bleu_score, **rouge_score, **bert_score}\n",
        "\n",
        "    filename = f\"e-{epoch}-test-scores-v{version}.csv\"\n",
        "    score_df = pd.DataFrame(data=all_scores)\n",
        "\n",
        "    score_df.to_csv(\n",
        "        model_path + \"/results/\" + filename, index=False, header=None\n",
        "    )\n",
        "\n",
        "\"\"\"Training\"\"\"\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Epoch:\", epoch+1)\n",
        "  train_loss = 0.0\n",
        "  batch_num = 1\n",
        "  for idx, batch in enumerate(train_dataloader):\n",
        "    print(\"Batch: \", str(batch_num))\n",
        "    batch_num +=1\n",
        "    torch.cuda.empty_cache()\n",
        "    input_ids = batch.pop(\"input_ids\").to(device)\n",
        "    pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "\n",
        "    outputs = model(input_ids=input_ids,\n",
        "                    pixel_values=pixel_values,\n",
        "                    labels=input_ids)\n",
        "\n",
        "    loss = outputs.loss\n",
        "    train_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  # Compute the average loss for the training dataset\n",
        "  train_loss /= len(train_dataloader.dataset)\n",
        "\n",
        "  # Print the training and validation losses for each epoch\n",
        "  print('Epoch [{}/{}], Train Loss: {:.4f}'\n",
        "        .format(epoch + 1, epochs, train_loss))\n",
        "\n",
        "  if epoch == 0 or (epoch + 1) % each_n_epoch == 0:\n",
        "      model.eval()\n",
        "      predict_and_save(model, epoch + 1)\n",
        "      os.makedirs(model_path + \"/weights/epoch\" + str(epoch+1) , exist_ok=True)\n",
        "      model.save_pretrained(model_path + \"/weights/epoch\" + str(epoch+1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(model_path + \"/results/running_time.json\", \"w+\") as f:\n",
        "    json.dump({\n",
        "        \"task\": \"caption\",\n",
        "        \"total_running_time_mins\": (time.time() - start_time) / 60,\n",
        "        \"version\": version,\n",
        "    }, f)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "qE07YMlAku7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}